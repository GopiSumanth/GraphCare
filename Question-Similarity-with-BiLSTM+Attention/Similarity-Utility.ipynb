{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Input, Layer, Embedding, LSTM, Dense, Flatten, Activation, RepeatVector, Permute, Lambda, \\\n",
    "Bidirectional, TimeDistributed, Dropout, Conv1D, GlobalMaxPool1D\n",
    "from keras.layers.merge import multiply, concatenate\n",
    "import keras.backend as K\n",
    "from util import make_w2v_embeddings, split_and_zero_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11715"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "embeddings = np.load('./embeddings.npy')\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "n_epoch = 50\n",
    "n_hidden = 50\n",
    "embedding_dim = 300\n",
    "max_seq_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManDist(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.result = None\n",
    "        super(ManDist, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(ManDist, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, **kwargs):\n",
    "        self.result = K.exp(-K.sum(K.abs(x[0] - x[1]), axis=1, keepdims=True))\n",
    "        return self.result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return K.int_shape(self.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_model(_input):\n",
    "    len_embeddings = 11715\n",
    "    embedded = Embedding(len_embeddings, embedding_dim, weights=[embeddings], input_shape=(max_seq_length,), \\\n",
    "                         trainable=False)(_input)\n",
    "\n",
    "    # Bi-LSTM\n",
    "    activations = Bidirectional(LSTM(n_hidden, return_sequences=True), merge_mode='concat')(embedded)\n",
    "    activations = Bidirectional(LSTM(n_hidden, return_sequences=True), merge_mode='concat')(activations)\n",
    "\n",
    "    # dropout\n",
    "    activations = Dropout(0.5)(activations)\n",
    "\n",
    "    # Attention\n",
    "    attention = TimeDistributed(Dense(1, activation='tanh'))(activations)\n",
    "    attention = Flatten()(attention)\n",
    "    attention = Activation('softmax')(attention)\n",
    "    attention = RepeatVector(n_hidden * 2)(attention)\n",
    "    attention = Permute([2, 1])(attention)\n",
    "    sent_representation = multiply([activations, attention])\n",
    "    sent_representation = Lambda(lambda x_lambda: K.sum(x_lambda, axis=1))(sent_representation)\n",
    "\n",
    "    # DropOut\n",
    "    sent_representation = Dropout(0.1)(sent_representation)\n",
    "\n",
    "    return sent_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    left_input = Input(shape=(max_seq_length,), dtype='float32')\n",
    "    right_input = Input(shape=(max_seq_length,), dtype='float32')\n",
    "    left_sen_representation = shared_model(left_input)\n",
    "    right_sen_representation = shared_model(right_input)\n",
    "\n",
    "\n",
    "    man_distance = ManDist()([left_sen_representation, right_sen_representation])\n",
    "    sen_representation = concatenate([left_sen_representation, right_sen_representation, man_distance])\n",
    "    similarity = Dense(1, activation='sigmoid')(Dense(2)(Dense(4)(Dense(16)(sen_representation))))\n",
    "    model = Model(inputs=[left_input, right_input], outputs=[similarity])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = create_model()\n",
    "    model.load_weights('./data/SiameseLSTM.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 10, 300)      3514500     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 300)      3514500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 10, 100)      140400      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 10, 100)      140400      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 10, 100)      60400       bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 10, 100)      60400       bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 10, 100)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 10, 100)      0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 10, 1)        101         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 1)        101         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 10)           0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 100, 10)      0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 100, 10)      0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 10, 100)      0           repeat_vector[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 10, 100)      0           repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 10, 100)      0           dropout[0][0]                    \n",
      "                                                                 permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 100)      0           dropout_2[0][0]                  \n",
      "                                                                 permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 100)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 100)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "man_dist (ManDist)              (None, 1)            0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 201)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 man_dist[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           3232        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            68          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            10          dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            3           dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,434,115\n",
      "Trainable params: 405,115\n",
      "Non-trainable params: 7,029,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_zero_padding(df, max_seq_length):\n",
    "    import itertools\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "    X = {'left': df['question1_n'], 'right': df['question2_n']}\n",
    "\n",
    "    for dataset, side in itertools.product([X], ['left', 'right']):\n",
    "        dataset[side] = pad_sequences(dataset[side], padding='pre', truncating='post', maxlen=max_seq_length)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word_list(text):\n",
    "    import re\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_w2v_embeddings(word2vec, df, embedding_dim):\n",
    "    vocabs = {}\n",
    "    vocabs_cnt = 0\n",
    "\n",
    "    vocabs_not_w2v = {}\n",
    "    vocabs_not_w2v_cnt = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if index != 0 and index % 1000 == 0:\n",
    "            print(str(index) + \" sentences embedded.\")\n",
    "\n",
    "        for question in ['question1', 'question2']:\n",
    "            q2n = []\n",
    "            words = text_to_word_list(row[question])\n",
    "\n",
    "            for word in words:\n",
    "                if word not in word2vec and word not in vocabs_not_w2v:\n",
    "                    vocabs_not_w2v_cnt += 1\n",
    "                    vocabs_not_w2v[word] = 1\n",
    "                if word not in vocabs:\n",
    "                    vocabs_cnt += 1\n",
    "                    vocabs[word] = vocabs_cnt\n",
    "                    q2n.append(vocabs_cnt)\n",
    "                else:\n",
    "                    q2n.append(vocabs[word])\n",
    "            df.at[index, question + '_n'] = q2n\n",
    "\n",
    "    embeddings = 1 * np.random.randn(len(vocabs) + 1, embedding_dim)\n",
    "\n",
    "    embeddings[0] = 0 \n",
    "\n",
    "    for index in vocabs:\n",
    "        vocab_word = vocabs[index]\n",
    "        if vocab_word in word2vec:\n",
    "            embeddings[index] = word2vec[vocab_word]\n",
    "    del word2vec\n",
    "\n",
    "    return df, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>question1_n</th>\n",
       "      <th>question2_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are some special cares for someone with a...</td>\n",
       "      <td>How can I keep my nose from getting stuffy at ...</td>\n",
       "      <td>What are some special cares for someone with a...</td>\n",
       "      <td>How can I keep my nose from getting stuffy at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What are some special cares for someone with a...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  How can I keep my nose from getting stuffy at ...   \n",
       "\n",
       "                                         question1_n  \\\n",
       "0  What are some special cares for someone with a...   \n",
       "\n",
       "                                         question2_n  \n",
       "0  How can I keep my nose from getting stuffy at ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ =  pd.DataFrame([[\"What are some special cares for someone with a nose that gets stuffy during the night?\", \"How can I keep my nose from getting stuffy at night?\"]], columns=[\"question1\", \"question2\"])\n",
    "for q in ['question1', 'question2']:\n",
    "    df_[q + '_n'] = df_[q]\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]], dtype=int32), 'right': array([[17, 18, 19, 20, 21, 10, 22, 23, 13, 24]], dtype=int32)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-4f87d5fd08d4>:17: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word not in word2vec and word not in vocabs_not_w2v:\n"
     ]
    }
   ],
   "source": [
    "train_df, embeddings = make_w2v_embeddings(word2vec=embeddings, df=df_, embedding_dim=embedding_dim)\n",
    "split_df = split_and_zero_padding(train_df, max_seq_length)\n",
    "print(split_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert split_df['left'].shape == split_df['right'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_sentence(user_input):\n",
    "    is_duplicate = model.predict([split_df['left'], split_df['right']])\n",
    "    return is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = find_similar_sentence(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97782946]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
